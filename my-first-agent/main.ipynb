{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76bc3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, json\n",
    "\n",
    "client = openai.OpenAI()\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53048df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city):\n",
    "    return \"33 degrees celcius.\"\n",
    "\n",
    "\n",
    "FUNCTION_MAP = {\n",
    "    \"get_weather\": get_weather,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c4b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"A function to get the weather of a city.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city to get the weather of.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed817e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat import ChatCompletionMessage\n",
    "\n",
    "\n",
    "def process_ai_response(message: ChatCompletionMessage):\n",
    "    if message.tool_calls:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": message.content or \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": tool_call.function.name,\n",
    "                            \"arguments\": tool_call.function.arguments,\n",
    "                        },\n",
    "                    }\n",
    "                    for tool_call in message.tool_calls\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for tool_call in message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "\n",
    "            print(f\"Calling function: {function_name} with {arguments}\")\n",
    "\n",
    "            try:\n",
    "                arguments = json.loads(arguments)\n",
    "            except json.JSONDecodeError:\n",
    "                arguments = {}\n",
    "\n",
    "            function_to_run = FUNCTION_MAP.get(function_name)\n",
    "\n",
    "            result = function_to_run(**arguments)\n",
    "\n",
    "            print(f\"Ran {function_name} with args {arguments} for a result of {result}\")\n",
    "\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": \"\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": result,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        call_ai()\n",
    "    else:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": message.content})\n",
    "        print(f\"AI: {message.content}\")\n",
    "\n",
    "\n",
    "def call_ai():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=messages,\n",
    "        tools=TOOLS,\n",
    "    )\n",
    "    print(f\"AI: {response}\")\n",
    "    process_ai_response(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48681819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, I'm Funi\n",
      "AI: ChatCompletion(id='chatcmpl-CY7ikSUdN3cMoHOWFSfCyZy1A8DKv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hi Funi! Nice to meet you. How can I help today? I can do things like:\\n\\n- Answer questions and explain concepts\\n- Help with writing, editing, and brainstorming\\n- Plan trips, events, or study schedules\\n- Generate ideas or code snippets\\n- Look up weather (if you tell me your city)\\n\\nWhat would you like to start with? If you want the weather, just tell me your city.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762248866, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=544, prompt_tokens=145, total_tokens=689, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=448, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "AI: Hi Funi! Nice to meet you. How can I help today? I can do things like:\n",
      "\n",
      "- Answer questions and explain concepts\n",
      "- Help with writing, editing, and brainstorming\n",
      "- Plan trips, events, or study schedules\n",
      "- Generate ideas or code snippets\n",
      "- Look up weather (if you tell me your city)\n",
      "\n",
      "What would you like to start with? If you want the weather, just tell me your city.\n",
      "User: What is the weather in Madrid?\n",
      "AI: ChatCompletion(id='chatcmpl-CY7j2K9dzQrhELgmNkFKSFX3Go7vp', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_gkqF5Epj4EUvflWZJrIzhnR5', function=Function(arguments='{\"city\":\"Madrid\"}', name='get_weather'), type='function')]))], created=1762248884, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=151, prompt_tokens=249, total_tokens=400, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Calling function: get_weather with {\"city\":\"Madrid\"}\n",
      "Ran get_weather with args {'city': 'Madrid'} for a result of 33 degrees celcius.\n",
      "AI: ChatCompletion(id='chatcmpl-CY7j7ZGCTuGluANB8RdCbWEJIAF6E', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Madrid is about 33°C right now (roughly 91°F).\\n\\nTips: it’s quite warm—stay hydrated, wear light clothing, and use sunscreen.\\n\\nWant an hourly forecast or a 5-day outlook, or prefer I convert to Fahrenheit for you?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762248889, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=702, prompt_tokens=282, total_tokens=984, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=640, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "AI: Madrid is about 33°C right now (roughly 91°F).\n",
      "\n",
      "Tips: it’s quite warm—stay hydrated, wear light clothing, and use sunscreen.\n",
      "\n",
      "Want an hourly forecast or a 5-day outlook, or prefer I convert to Fahrenheit for you?\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"Send a message to the LLM...\")\n",
    "    if message == \"quit\" or message == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        print(f\"User: {message}\")\n",
    "        call_ai()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
